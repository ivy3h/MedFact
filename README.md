# MedFact: Benchmarking the Fact-Checking Capabilities of Large Language Models on Chinese Medical Texts

ðŸ”¥ **[09/18/2025] Update**: We released [**MedFact**](https://arxiv.org/abs/2509.12440), a benchmark for fact-checking on Chinese medical texts. ðŸ‘‰ Visit our [project page](https://ivy3h.github.io/medfact.github.io/).ðŸ¥³

## Overview
MedFact a challenging benchmark for Chinese medical fact-checking, which is curated from diverse real-world texts such as medical encyclopedias. It comprises 2,116 expert-annotated medical texts that span 13 medical specialties, 8 fine-grained error types, 4 writing styles, and 5 difficulty levels.

## Citation
```bibtex
@misc{he2025medfactbenchmarkingfactcheckingcapabilities,
      title={MedFact: Benchmarking the Fact-Checking Capabilities of Large Language Models on Chinese Medical Texts}, 
      author={Jiayi He and Yangmin Huang and Qianyun Du and Xiangying Zhou and Zhiyang He and Jiaxue Hu and Xiaodong Tao and Lixian Lai},
      year={2025},
      eprint={2509.12440},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2509.12440}, 
}
